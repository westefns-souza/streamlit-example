# -*- coding: utf-8 -*-
import re
import pandas as pd
import networkx as nx
from pyvis.network import Network
from IPython.core.display import display, HTML
import matplotlib.pyplot as plt
import streamlit as st
import csv

with st.echo(code_location='below'):
    st.title('Trabalho analise redes twitter')

    st.markdown(
        """Trabalho_analise_redes_twitter.ipynb

        Automatically generated by Colaboratory.

        Original file is located at
            https://colab.research.google.com/drive/1kLKQ07znezFdOoKkf1rvjxf27DcMFeRY

        # Analise da base de dados do twitter
        """
    )

    st.markdown(
    """# Limpando a base
    Como a base não tinha um csv bom, tive que limpar principalmente a coluna 'friends' que estava como um array separado por vírgula, com isso a leitura quebrava no momento de abrir e ler os dados com o pandas. 

    Achei Uma função de substituir_virgulas usando regex para identicar apenas as frases dentro de um array [ ]. 
    """
    )
    
    def substituir_virgulas(texto):
        padrao = r'\[(.*?)\]'  
        matches = re.findall(padrao, texto)  
        for match in matches:
            novo_texto = match.replace(',', ';')  
            texto = texto.replace(match, novo_texto) 
        return texto

    st.markdown(
        """## Criando um novo arquivo já corrigido

        Para que não precise trabalhar com os dados em memória sempre
        """
    )

    with open("/content/data_twitter.csv") as file:
        with open("/content/data_twitter_formated.csv", "w") as new_file:
            for line in file:
                new_file.write(substituir_virgulas(line))

    st.markdown("""Carregando os dados do arquivo formatado para um DateFrame""")
    
    df = pd.read_csv('/content/data_twitter_formated.csv', on_bad_lines="skip")
    st.write(df)

    st.markdown("""Selecionando apenas as linhas que estou utilizando""")

    df_reduced = df[['id', 'friends']]
    st.write(df_reduced)

    st.markdown("""Separando as edges juntamente com os nós, foi necessário porque o coluna de friends se torna uma lista""")

    nodes = []
    edges = []

    for line in df_reduced.values.tolist():
        userId = int(line[0])
        nodes.append(userId)

        friends = line[1].replace('[', '').replace('; ]', '').replace(']', '').replace('"', '').split(';')

        for friend in friends:
            friend = friend.strip()
            if friend != '':
                friend = int(friend)
                nodes.append(friend)
                edges.append([userId, friend])

    st.markdown("""Criando um arquvivo apenas com os nós para usar depois sem precisar dos passos acima""")

    with open('base_reduzida.csv', 'w', newline='') as csvfile:
        fieldnames = ['userId', 'friendId']
        writer = csv.DictWriter(csvfile, fieldnames)
        
        writer.writeheader()
        for linha in edges:
            writer.writerow({'userId': linha[0], 'friendId': linha[1]})

    st.markdown("""# Usando apartir da base reduzida para criar od dados""")

    df_base_reduzida = pd.read_csv('/content/base_reduzida.csv', on_bad_lines="skip")
    st.markdown(df_base_reduzida)

    st.markdown("""## Criando o Grafico com NetworkX""")

    G = nx.Graph()

    for line in df_base_reduzida.values.tolist():
        G.add_nodes_from(line)
        G.add_edges_from([(line[0], line[1])])

    st.markdown("""## Gerando o gráfico com o Pyvis""")

    nt = Network('500px', '100%', notebook=True, cdn_resources='in_line')
    nt.from_nx(G)
    nt.show('grafico.html')
    st.markdown(display(HTML('grafico.html')))

    st.markdown("""# Obtendo os dados pedidos na máteria""")

    st.markdown("""## Obtendo a matriz de adjacência""")

    adj_matrix = nx.to_pandas_adjacency(G)

    plt.imshow(adj_matrix, cmap='binary', origin='upper')
    plt.xlabel('Nós')
    plt.ylabel('Nós')
    plt.title('Matriz de Adjacência')
    plt.colorbar()
    st.write(plt.show())

    st.markdown("""## Calcular o diâmetro""")

    diameter = nx.diameter(G)
    st.write("Diâmetro: ", diameter)

    st.markdown("""## Calcular a periferia""")

    periphery = nx.periphery(G)

    print("Periferia: ", periphery)

    st.markdown(""" ## Histograma de distribuição empírica de grau.""")

    hist = nx.degree_histogram(G)
    degrees = list(range(len(hist)))
    frequencies = hist

    nt = Network(height="500px", width="100%", notebook=True,cdn_resources='in_line')
    nt.from_nx(G)

    for degree, freq in zip(degrees, frequencies):
        nt.add_node(degree, size=freq)
    
    nt.show("histograma.html")
    st.write(display(HTML('histograma.html')))

    st.markdown("""## Coeficiente de clustering local para nós escolhidos.""")

    coefs_clustering = nx.clustering(G, [1969527638])
    st.write(coefs_clustering)

    st.markdown("""## Calcular o coeficiente de clustering global""")

    coef_clustering = nx.average_clustering(G)
    st.write(coef_clustering)

    st.markdown("""## Encontrar os componentes conectados fortemente""")

    componentes_fortemente = nx.strongly_connected_components(G)
    st.write(componentes_fortemente)

    st.markdown("""## Encontrar os componentes conectados fracamente""")

    componentes_fracamente = nx.weakly_connected_components(G)
    st.write(componentes_fracamente)

    st.markdown("""## Calcular a centralidade de grau""")

    centrality = nx.degree_centrality(G)

    for node, centrality_value in centrality.items():
        st.write("Nó:", node, "Centralidade de Grau: ", centrality_value)

    st.markdown("""## Calcular a centralidade de proximidade""")

    centrality = nx.closeness_centrality(G)

    for node, centrality_value in centrality.items():
        st.write("Nó:", node, "Centralidade de Proximidade: ", centrality_value)

    st.markdown("""## Calcular o Betweenness centrality""")

    centrality = nx.betweenness_centrality(G)

    for node, centrality_value in centrality.items():
        st.write("Nó:", node, "Centralidade de Intermediação: ", centrality_value)

    st.markdown("""## Calcular a centralidade de eigenvector""")

    centrality = nx.eigenvector_centrality(G)

    for node, centrality_value in centrality.items():
        st.write("Nó:", node, "Centralidade de Eigenvector: ", centrality_value)

    st.markdown("""## Calcular a assortatividade geral""")

    assortativity = nx.degree_assortativity_coefficient(G)
    st.write(assortativity)
